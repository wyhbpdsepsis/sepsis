# python代码
#缺失值的python代码
import pandas as pd
import matplotlib
from matplotlib import pyplot
import matplotlib.pyplot as plt
import missingno as msno
%matplotlib inline
df = pd.read_csv('C:/Users/hmoye/Desktop/BPD8-23_1.csv')
df
msno.matrix(df)
path ='C:/Users/hmoye/Desktop/'
fig = plt.figure(figsize=(16,8))
msno.matrix(df)
fig = plt.gcf()
plt.show()
fig.savefig(path+'missingno7.svg',format='svg',dip=300)
msno.bar(df)
fig = plt.gcf()
# 显示图形
plt.show() 
# 保存图形为PDF
plt.savefig('missing_values_bar1.pdf')
 
#机器学习模型的拟合及SHAP的python代码
#### Load the necessary modules###
import pandas as pd
import numpy as np
import pickle
import matplotlib
from matplotlib import pyplot
import matplotlib.pyplot as plt
import seaborn as sns
sns.set(style='whitegrid', rc={'axes.grid': False})
from itertools import cycle
from sklearn.model_selection import train_test_split,StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn import svm
from sklearn.svm import LinearSVC
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.ensemble import AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn import model_selection
from sklearn.model_selection import train_test_split
from collections import Counter
from sklearn.model_selection import cross_val_score
from sklearn import metrics
from sklearn.metrics import roc_curve, auc, precision_recall_curve, f1_score, roc_auc_score
from sklearn.metrics import accuracy_score, classification_report 
from sklearn.metrics import cohen_kappa_score
from sklearn.metrics import confusion_matrix
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image
from io import BytesIO
from scipy.stats import norm,t
from tqdm import tqdm
from sklearn.utils import resample
from sklearn.datasets import make_classification
from collections import Counter
from matplotlib import pyplot
from numpy import where
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline
import shap
from sklearn.preprocessing import StandardScaler
from sklearn.calibration import CalibratedClassifierCV
from sklearn.base import clone
from scipy import interp
from collections import Counter
from matplotlib import pyplot
from numpy import where
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline
#Read in ML input 
    #samples as rows with last column as cohort for classification
df = pd.read_csv('C:/Users/hmoye/Desktop/sepsis文件夹/5-31/BPD5-31_25.csv')
#Set up ML variables: x1 is df with feature values; y1 is cohort for classification
X1 = df.drop(['sepsis'],axis=1)
y1 = df.sepsis
X1 = StandardScaler().fit_transform(X1)
data = pd.DataFrame(X1)
data.describe([0.01,0.05,0.1,0.25,0.5,0.75,0.9,0.99]).T
from sklearn.datasets import make_classification
#Random oversample with SMOTE
oversample = SMOTE()
X, y = oversample.fit_resample(X1, y1)
# 初始化设置
shap.initjs()
plt.style.use('seaborn')
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False
# 配置参数
plt.style.use('seaborn')
seed = 1
models = [
    ('LR', LogisticRegression(random_state=seed)),
    ('RF', RandomForestClassifier(random_state=seed)),
    ("SVM", svm.SVC(probability=True,random_state=seed)),
    ('DTREE', DecisionTreeClassifier(random_state=seed)),
    ('ADB', AdaBoostClassifier(random_state=seed)),
    ('NB', GaussianNB()),
    ('LDA', LinearDiscriminantAnalysis()),
    ('KNN', KNeighborsClassifier(n_neighbors=3)),
    ('GB', GradientBoostingClassifier(random_state=seed)),
    ('MLP', MLPClassifier())
]
n_bootstraps = 1000
def bootstrap_evaluation():
    results = []
    roc_data = {}
    mean_fpr = np.linspace(0, 1, 100)
    for name, model in tqdm(models, desc='Models'):
        auc_scores, f1_scores = [], []
        sensitivities, specificities = [], []
        tprs = []
        for _ in tqdm(range(n_bootstraps), desc=name, leave=False):
            # Bootstrap抽样
            idx = resample(np.arange(len(y)), stratify=y, replace=True)
            X_boot, y_boot = X[idx], y[idx]
            
            # 训练模型
            model.fit(X_boot, y_boot)
            
            # 预测完整数据集
            if hasattr(model, "predict_proba"):
                y_proba = model.predict_proba(X)[:, 1]
            else:
                y_proba = model.decision_function(X)
            y_pred = (y_proba > 0.5).astype(int)
            
            # 计算指标
            auc = roc_auc_score(y, y_proba)
            auc_scores.append(roc_auc_score(y, y_proba))
            f1_scores.append(f1_score(y, y_pred))
            
            # 计算混淆矩阵
            tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()
            sensitivities.append(tp / (tp + fn))
            specificities.append(tn / (tn + fp))
            # 新增：计算ROC曲线的fpr和tpr
            fpr, tpr, _ = roc_curve(y, y_proba)
            # 插值到mean_fpr网格上
            interp_tpr = np.interp(mean_fpr, fpr, tpr)
            interp_tpr[0] = 0.0  # 初始点设置为0
            tprs.append(interp_tpr)
        
        # 计算统计量
        def bootstrap_stats(values):
            mean = np.mean(values)
            std = np.std(values)
            ci = np.percentile(values, [2.5, 97.5])
            return mean, std, ci
        
        auc_mean, auc_std, auc_ci = bootstrap_stats(auc_scores)
        f1_mean, f1_std, f1_ci = bootstrap_stats(f1_scores)
        sens_mean, sens_std, _ = bootstrap_stats(sensitivities)
        spec_mean, spec_std, _ = bootstrap_stats(specificities)    
        # 存储结果
        results.append({
            'Model': name,
            'AUC Mean': auc_mean,
            'AUC CI': auc_ci,
            'F1 Mean': f1_mean,
            'F1 CI': f1_ci,
            'Sensitivity Mean': sens_mean,
            'Sensitivity Std': sens_std,
            'Specificity Mean': spec_mean,
            'Specificity Std': spec_std
        })
    
       # 新增：保存ROC曲线数据
        mean_tpr = np.mean(tprs, axis=0)
        mean_tpr[-1] = 1.0  # 最后一个点设置为1
        std_tpr = np.std(tprs, axis=0)
        tprs_upper = np.minimum(mean_tpr + 1.96*std_tpr, 1)
        tprs_lower = np.maximum(mean_tpr - 1.96*std_tpr, 0)
    
        roc_data[name] = {
            'mean_fpr': mean_fpr,
            'mean_tpr': mean_tpr,
            'tprs_upper': tprs_upper,
            'tprs_lower': tprs_lower,
            'auc_mean': auc_mean,
            'auc_ci': auc_ci
        }
 
      # 新增：绘制所有模型的ROC曲线
    plt.figure(figsize=(10, 8))
    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=0.8)
    colors = plt.cm.tab10(np.linspace(0, 1, 10))
    for i,(name, data) in enumerate(roc_data.items()):
        current_color = colors[i]
        plt.plot(data['mean_fpr'], data['mean_tpr'], color = current_color,
                 label=f'{name} (AUC = {data["auc_mean"]:.2f} [{data["auc_ci"][0]:.2f}-{data["auc_ci"][1]:.2f}])',
                 lw=2, alpha=0.8)
        plt.fill_between(data['mean_fpr'], data['tprs_lower'], data['tprs_upper'],color = current_color,
                         alpha=0.2)
 
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curves of Multiple Models')
    plt.legend(loc='lower right')
    plt.savefig("output25.pdf", format="pdf", dpi=300, bbox_inches="tight")
    plt.show()
　　return pd.DataFrame(results)
　　print("\n正在进行Bootstrap评估...")
　　boot_results = bootstrap_evaluation()
　　print("\nBootstrap结果：")
　　print(boot_results.round(3))
　　boot_results.to_csv('bootstrap_results4.csv', index=False)
　　 
　　# 初始化设置
　　shap.initjs()
　　plt.style.use('seaborn')
　　plt.rcParams['font.sans-serif'] = ['SimHei']
　　plt.rcParams['axes.unicode_minus'] = False
　　# 训练随机森林分类器
　　model = RandomForestClassifier(random_state=1).fit(X,y)
　　# 创建SHAP解释器并计算SHAP值
　　explainer = shap.TreeExplainer(model)
　　shap_values = explainer.shap_values(X)  # 获取Explanation对象
　　shap.summary_plot(shap_values[1], X.astype("float"),max_display=36,show=False)
　　plt.savefig('shap_rf.pdf')
　　 
